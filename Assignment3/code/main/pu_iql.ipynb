{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "42f01e172752d5b7",
            "metadata": {},
            "source": [
                "## IQL for Pursuit"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3de43f09",
            "metadata": {},
            "source": [
                "\n",
                "### Arguments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "878b31ffd54e59f5",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-05-24T10:07:12.889584Z",
                    "start_time": "2025-05-24T10:07:12.886339Z"
                }
            },
            "outputs": [],
            "source": [
                "NUM_AGENTS: int = 10\n",
                "MAX_CYCLES: int = 200\n",
                "NUM_EPISODES: int = 150\n",
                "MAX_EPISODES_LEN: int = 150\n",
                "# target DQN update/freeze frequency\n",
                "DQN_UPDATE_FREQ: int = 25\n",
                "\n",
                "SHOW_PLOT: bool = False\n",
                "RENDER: bool = False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "db1c720a04a1f2ca",
            "metadata": {},
            "source": [
                "### Main Trainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "initial_id",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-05-24T10:07:14.965229Z",
                    "start_time": "2025-05-24T10:07:13.004118Z"
                }
            },
            "outputs": [],
            "source": [
                "from a3marl.envs.utils import EnvConfig\n",
                "from a3marl.agents import IqlAgent, IqlAgentConfig\n",
                "from a3marl.trainer import iql_trainer\n",
                "from pettingzoo.sisl import pursuit_v4\n",
                "\n",
                "\n",
                "def main() -> None:\n",
                "    pursuit_config: EnvConfig = EnvConfig(\n",
                "        name_abbr=\"pu\",\n",
                "        env_creator=pursuit_v4.parallel_env,\n",
                "        env_kwargs={\n",
                "            \"n_pursuers\": NUM_AGENTS,\n",
                "            \"max_cycles\": MAX_CYCLES,\n",
                "            \"n_catch\": 1,\n",
                "        },\n",
                "    )\n",
                "\n",
                "    env = pursuit_config.get_env(\n",
                "        render_mode=\"human\" if RENDER else None,\n",
                "    )\n",
                "\n",
                "    states, info = env.reset()\n",
                "    obs_dims = dict([(agent_key, state.size) for agent_key, state in states.items()])\n",
                "    act_dims = dict([(agent_key, int(env.action_space(agent_key).n)) for agent_key in obs_dims.keys()])\n",
                "\n",
                "    cur_agents = {\n",
                "        agent_key: IqlAgent(sid=agent_key, config=IqlAgentConfig(\n",
                "            obs_dim=obs_dims[agent_key],\n",
                "            act_dim=act_dims[agent_key],\n",
                "            hidden_dims=[100, 50, 25],\n",
                "            batch_size=256,\n",
                "            lr=1e-3,\n",
                "            grad_clip_value=5,\n",
                "            gamma=0.95,\n",
                "            eps_start=0.9,\n",
                "            eps_decay=0.95,\n",
                "            eps_min=0.05,\n",
                "            mem_size=10_000,\n",
                "        ), act_sampler=env.action_space(agent_key).sample)\n",
                "        for agent_key in states.keys()\n",
                "    }\n",
                "\n",
                "    iql_trainer(\n",
                "        env=env,\n",
                "        env_config=pursuit_config,\n",
                "        cur_agents=cur_agents,\n",
                "        num_episodes=NUM_EPISODES,\n",
                "        max_episode_lengths=MAX_EPISODES_LEN,\n",
                "        dqn_update_freq=DQN_UPDATE_FREQ,\n",
                "        show_plot=SHOW_PLOT,\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "84e3e466c8c48e37",
            "metadata": {},
            "source": [
                "### Run"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "2908646ef0123089",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-05-24T11:37:57.938055Z",
                    "start_time": "2025-05-24T10:07:14.974305Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Episode 0\tAvg return = -4.6810;\n",
                        "-4.71033 vs best: -inf, update Target DQN\n",
                        "-4.68705 vs best: -4.71033, update Target DQN\n",
                        "-4.49730 vs best: -4.68705, update Target DQN\n",
                        "-4.36324 vs best: -4.49730, update Target DQN\n",
                        "-4.13972 vs best: -4.36324, update Target DQN\n",
                        "-4.12780 vs best: -4.13972, update Target DQN\n",
                        "-4.07740 vs best: -4.12780, update Target DQN\n",
                        "-3.60359 vs best: -4.07740, update Target DQN\n",
                        "Episode 10\tAvg return = -4.4049;\n",
                        "Episode 20\tAvg return = -4.4063;\n",
                        "-3.59309 vs best: -3.60359, update Target DQN\n",
                        "Episode 30\tAvg return = -4.2745;\n",
                        "Episode 40\tAvg return = -4.4725;\n",
                        "Episode 50\tAvg return = -4.2831;\n",
                        "Episode 60\tAvg return = -4.2028;\n",
                        "Episode 70\tAvg return = -4.3326;\n",
                        "-3.58669 vs best: -3.59309, update Target DQN\n",
                        "-3.29506 vs best: -3.58669, update Target DQN\n",
                        "Episode 80\tAvg return = -4.3639;\n",
                        "-2.99143 vs best: -3.29506, update Target DQN\n",
                        "Episode 90\tAvg return = -4.0940;\n",
                        "Episode 100\tAvg return = -4.2337;\n",
                        "Episode 110\tAvg return = -4.2227;\n",
                        "Episode 120\tAvg return = -4.2152;\n",
                        "Episode 130\tAvg return = -4.0930;\n",
                        "Episode 140\tAvg return = -3.6046;\n"
                    ]
                }
            ],
            "source": [
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "rl",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}